\documentclass[11pt]{article}
\usepackage[a4paper,left=0.7in,right=0.7in,top=0.6in,bottom=1in]{geometry}
\usepackage{graphicx}
\usepackage{url}
\usepackage{datetime}
\linespread{1.2}

\title{\textbf{CS296 Basecode : An Analysis}}
\author{
  Shyam JVS\\
  120050052\\
  \texttt{shyam123.jvs95@gmail.com}
  \and
  Soma Naik\\
  120050080\\
  \texttt{somanaik2411@gmail.com}
  \and
  Sumanth Vakulabharanam\\
  120050069\\
  \texttt{sumanthbharan@gmail.com}\\
}
\date{\today}

\begin{document}

\maketitle
\section{Introduction}
In this document, we provide a detailed analysis of the basecode, obtained by timing and profiling it. Also, we discuss the performance of the basecode in different situations and some ways of optimizing it. An effort has been made to observe and explain some interesting patterns in the timing data, the concerning plots and caller graphs.

\section{Timing Insights from Lab 5}

\subsection{Variation of time with respect to number of iterations}
For simplicity and easier analysis, we have assumed the number of iterations to be ranging from 1 to 150. And have rerun the program 150 times for each iteration value in the range. The averaged time over reruns for calculations (of different attributes like position, velocity, step etc) for various iteration values, when plotted, turned out to be quite interesting. (See Figures below) \\

Firstly, we notice that the avg. loop time increases almost linearly with the no. of iterations.(See figure below) This is quite intuitive, as the number of loops is equal to the iteration value (n) and each iteration takes roughly the same time to finish (as there are just a few floating point operations in each iteration). Hence the loop time is increasing linearly with 'n'. 

\begin{center} 
\includegraphics [scale=0.45]{./images/g29_plot01.png} 
\end{center}

Next, observe that the avg. step time decreases with the value of 'n' initially. (See figure below for avg. step time vs 'n' plot, along with error bars) Greater values of the step time at the start can be reasoned out using the following logic that, initially the simulation has to adjust and validate the objects' dynamics and other conditions like overlap between rigid bodies, collision at various points etc, which may not be so significant later on. Note that the step time values can show slight ups and downs later on based on the situation of our World. Say if at some point there are many objects close to each other and possibly multiple collissions happening, then the step time may rise for a brief period, and hence increasing (/decreasing) the avg. step time as well. However, what is interesting is that, eventually, after a large number of iterations, the system stabilizes to an almost static state, where most of the bodies either settle down or move at constant rates. At this point the avg. step time becomes almost constant asymptotically.

\begin{center} 
\includegraphics [scale=0.45]{./images/g29_plot03.png} 
\end{center}

Now, consider the variation of avg. collision time, avg. velocity time and avg. position time with the iteration value. All these 3 variables show a similar variation to that of the avg. step time (see figure below). They remain almost constant with 'n', (with an initial fall due to reasons similar to that for step time) showing that the time taken for these operations is more or less the same for each step. These can slightly vary depending on the situation (similar to step time).

\begin{center} 
\includegraphics [scale=0.45]{./images/g29_plot02.png} 
\end{center}

The figure below shows the histogram plot of step times over the reruns for n = 80 (highest roll number of our group). The bars in the plot stand for the relative frequency of step times in that particular bucket. The mean value of step time comes out to be around 0.23ms . And it is evident that most of the frequency is concentrated around 0.23ms, and follows(roughly) a gaussian (bell-shaped) distribution around it as the mean. This is statistically consistant as per the central limit theorem. 

\begin{center} 
\includegraphics [scale=0.45]{./images/g29_plot04.png} 
\end{center}

\subsection{Performance on a heavily loaded system}
When we ran the base code with n = 20000 while the system was running free (without many heavy processes), it took around 2.890 seconds of running time on an average (measured using the 'time' command in linux). Now the system was loaded with some heavy programs such as libre packages, image viewer, a few memory-consuming C++ codes etc. The base code run with the same 'n', now took slightly more time to finish. It took about 2.910 seconds on an average. The increase is clearly due to lesser availability of system resources to the program. 

\subsection{Difference between measurements made using 'time' and 'gettimeofday'}
For n = 20000, average time required for execution of the base code using the 'time' command came out to be around 2896 ms. This accounts for the total real time used by the program (including the standard input and output). However, the total loop time measured by taking the difference of times between the begin and end of the 'for' loop inside the program, using gettimeofday() command is around 2892 ms. Note that this time will always be slightly less than the time shown by 'time' command. This is because, the 'time' command also includes the time taken by other steps in main.cpp not covered under the 'for' loop. (For instance, the call to the function 'print-info', which prints all the avg. times) \\


\section{Insights from the Profiled Base Code}

\subsection {Release Mode}
We have first compiled the Box2D and the other source files in the base code, using the release mode. This included the addition of -O3 flag to the compiler options of g++ and also running cmake on the Box2D package with '-DCMAKE\_BUILD\_TYPE=Release' option. \\
The following was the output of the simulation: \\ 
Number of Iterations: 100000 \\
Average time per step is 0.018725 ms \\
Average time for collisions is 0.001398 ms \\
Average time for velocity updates is 0.008144 ms \\
Average time for position updates is 0.002030 ms \\
Total loop time is 2842.357178 ms \\ \\
We have obtained the call graph for the profile as an image using the python script. This pictorially shows the calling relationships between various subroutines of the base code. The nodes represent functions and also information about the fraction of time taken by them in the total execution time . A directed edge from node 'a' to node 'b' represents the function call to 'b' from 'a'. This edge holds the information about how many times such a call is being made and the percentage of the time spent by calls to 'b' from 'a', out of all calls made from 'a'. \\
The call graph for this mode is shown below: \\
(The graph doesn't appear completely, as it is very long. To view the actual image, go to doc/images directory in the project root)

\begin{center} 
\includegraphics [scale=0.35]{./images/release_100000.png}
\end{center}


\subsection {Debug Mode}
Following the release mode, we again recompiled the Box2D and the other source files in the base code, but this time using the debug mode. This required the exclusion of the -O3 optimization flag from the previous options of g++ and also running cmake on the Box2D package with '-DCMAKE\_BUILD\_TYPE=Debug' option. \\
The following was the output of the simulation: \\ 
Number of Iterations: 100000 \\
Average time per step is 0.194600 ms \\
Average time for collisions is 0.016332 ms \\
Average time for velocity updates is 0.095302 ms \\
Average time for position updates is 0.015941 ms \\
Total loop time is 24498.611328 ms \\
The call graph for this mode is shown below: \\
(The graph doesn't appear completely, as it is very long. To view the actual image, go to doc/images directory in the project root)

\begin{center} 
\includegraphics [scale=0.35]{./images/debug_100000.png} 
\end{center}

\subsection {Differences between Debug and Release modes}
Debug and Release are different configurations for building a project. As the name implies, you generally use the Debug mode for debugging your project, and the Release mode for the final build for end users. The Debug mode does not optimize the binary it produces (as optimizations can greatly complicate debugging), and generates additional data to aid debugging. The Release mode enables optimizations and generates less (or no) extra debug data. \\
The -O compiler variable of g++ decides the overall level of optimization. This makes the code compilation take somewhat more time, and can take up much more memory, especially as you increase the level of optimization. 
In the release mode, we have added the -O3 optimization flag, which is the highest level of optimization possible with g++. It turns on optimizations that are expensive in terms of compile time and memory usage. \\
The following are the key observations and differences noted from the profile data generated using the debug and release modes:  

\begin{enumerate}
\item In release mode, maximum proportion of time is taken by the function \\ b2ContactSolver::SolveVelocityConstraints() which is about 33\%, whereas, in debug mode the same function takes only 10.7\% of the time, though it still remains the most time-consuming. 
\item In release mode, the function debug\_draw\_t::DrawSolidPolygon(b2Vec2 const*, int, b2Color const\&) is called the maximum number of times (2500000 times)among all functions and consumed about 1.05\% of the total time. Whereas in debug mode, the function b2Vec2::b2Vec2(float, float) is called the maximum number of times (610669356 times) and took 6.62\% of the total time.
\item Similarly, we can notice other such functions from the profile data and the call graph, which consume considerable amount of time to get a deeper insight into the functioning of the code.
\item It should be noted that, when we run the code with fewer iterations (in the range of 1000-10000) the total loop time is quite fluctuating. To avoid that and obtain stable results, we are using a large number of iterations (= 100000).
\item In the release mode, we are using the optimization option -O3 whereas in the debug mode we are not using any optimization options. Hence the total loop time in release mode (2842.357178 ms) is about one-tenth of the total loop time in debug mode (24498.611328 ms), for the same number of iterations. It is therefore clear that this option (-O3) increases the compile time and memory usage but decreases the execution time.
\end{enumerate}

\subsection{Some suggestions for Optimization of the base code}
Most of the time is taken by the function \textbf{b2ContactSolver::SolveVelocityConstraints()} in the Box2D library in both the modes. So if we can optimize this function we can significantly reduce the total loop time. This is one such instance of a possible optimization. We could find more, by a more detailed inspection of the profile data. In general we could say it as a thumb rule that, functions that are called quite frequently or that consume more time should be optimized. Those functions which take almost the same time in both the modes should be focussed upon especially, as the -O3 option is not able to perform much optimization with them.

\end{document}
